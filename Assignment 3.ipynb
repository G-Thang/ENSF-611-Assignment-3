{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (37 total marks)\n",
    "### Due: October 24 at 11:59pm\n",
    "\n",
    "### Name: Gi-E Thang"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 1: Regression (14.5 marks)\n",
    "\n",
    "For this section, we will be continuing with the concrete example from yellowbrick. You will need to compare these results to the results from the previous assignment. Please use the results from the solution if you were unable to complete Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (0.5 marks)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "X, y = load_concrete()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0 marks)\n",
    "\n",
    "Data processing was completed in the previous assignment. No need to repeat here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import the Decision Tree, Random Forest and Gradient Boosting Machines regression models from sklearn\n",
    "2. Instantiate the three models with `max_depth = 5`. Are there any other parameters that you will need to set?\n",
    "3. Implement each machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the average training and validation accuracy using mean squared error with cross-validation. To do this, you will need to set `scoring='neg_mean_squared_error'` in your `cross_validate` function and negate the results (multiply by -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3f7a8",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: DT, RF and GB\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training Accuracy  Validation Accuracy\n",
      "DT          47.918561           163.087775\n",
      "RF          32.056464           156.251425\n",
      "GB           3.739270            99.224576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Instantiate the models\n",
    "decision_tree = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "random_forest = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "gradient_boosting = GradientBoostingRegressor(max_depth=5, random_state=0)\n",
    "\n",
    "# Fit the models with the data\n",
    "decision_tree.fit(X, y)\n",
    "random_forest.fit(X, y)\n",
    "gradient_boosting.fit(X, y)\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Perform cross-validation for each model\n",
    "dt_scores = cross_validate(decision_tree, X, y, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "rf_scores = cross_validate(random_forest, X, y, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "gb_scores = cross_validate(gradient_boosting, X, y, scoring='neg_mean_squared_error', cv=5, return_train_score=True)\n",
    "\n",
    "# Calculate the average training and validation accuracy\n",
    "dt_avg_train_mse = -np.mean(dt_scores['train_score'])\n",
    "dt_avg_val_mse = -np.mean(dt_scores['test_score'])\n",
    "rf_avg_train_mse = -np.mean(rf_scores['train_score'])\n",
    "rf_avg_val_mse = -np.mean(rf_scores['test_score'])\n",
    "gb_avg_train_mse = -np.mean(gb_scores['train_score'])\n",
    "gb_avg_val_mse = -np.mean(gb_scores['test_score'])\n",
    "\n",
    "# Create a pandas DataFrame for results\n",
    "results = pd.DataFrame({\n",
    "    'Training Accuracy': [dt_avg_train_mse, rf_avg_train_mse, gb_avg_train_mse],\n",
    "    'Validation Accuracy': [dt_avg_val_mse, rf_avg_val_mse, gb_avg_val_mse]\n",
    "}, index=['DT', 'RF', 'GB'])\n",
    "\n",
    "# Print the results\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31715a9d",
   "metadata": {},
   "source": [
    "Repeat the step above to print the R2 score instead of the mean-squared error. For this case, you can use `scoring='r2'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83539f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Training R2 Score  Validation R2 Score\n",
      "DT           0.822887             0.176210\n",
      "RF           0.881218             0.174781\n",
      "GB           0.986436             0.474425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "# Create a custom scorer for R2 score since it's not available directly in cross_validate\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "# Perform cross-validation for each model with R2 score\n",
    "dt_scores = cross_validate(decision_tree, X, y, scoring=r2_scorer, cv=5, return_train_score=True)\n",
    "rf_scores = cross_validate(random_forest, X, y, scoring=r2_scorer, cv=5, return_train_score=True)\n",
    "gb_scores = cross_validate(gradient_boosting, X, y, scoring=r2_scorer, cv=5, return_train_score=True)\n",
    "\n",
    "# Calculate the average training and validation R2 score\n",
    "dt_avg_train_r2 = np.mean(dt_scores['train_score'])\n",
    "dt_avg_val_r2 = np.mean(dt_scores['test_score'])\n",
    "rf_avg_train_r2 = np.mean(rf_scores['train_score'])\n",
    "rf_avg_val_r2 = np.mean(rf_scores['test_score'])\n",
    "gb_avg_train_r2 = np.mean(gb_scores['train_score'])\n",
    "gb_avg_val_r2 = np.mean(gb_scores['test_score'])\n",
    "\n",
    "# Create a pandas DataFrame for results with R2 score\n",
    "results_r2 = pd.DataFrame({\n",
    "    'Training R2 Score': [dt_avg_train_r2, rf_avg_train_r2, gb_avg_train_r2],\n",
    "    'Validation R2 Score': [dt_avg_val_r2, rf_avg_val_r2, gb_avg_val_r2]\n",
    "}, index=['DT', 'RF', 'GB'])\n",
    "\n",
    "# Print the results with R2 score\n",
    "print(results_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do these results compare to the results using a linear model in the previous assignment? Use values.\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "*ANSWER HERE*\n",
    "\n",
    "1.\n",
    "Results from Previous Assignment (Linear Models):\n",
    "\n",
    "Alpha = 0.001: Validation R2 score = 0.62\n",
    "Alpha = 0.01: Validation R2 score = 0.62\n",
    "Alpha = 0.1: Validation R2 score = 0.62\n",
    "Alpha = 1: Validation R2 score = 0.62\n",
    "Alpha = 10: Validation R2 score = 0.62\n",
    "\n",
    "Results from Current Assignment (Tree-Based Models):\n",
    "\n",
    "Decision Tree:\n",
    "Validation R2 score: 0.176210\n",
    "Random Forest:\n",
    "Validation R2 score: 0.174781\n",
    "Gradient Boosting:\n",
    "Validation R2 score: 0.474425\n",
    "The R2 scores for the tree-based models in the current assignment are significantly lower than the validation R2 scores for the linear models in the previous assignment. This indicates that, in terms of R2 score, the linear models performed better on the validation dataset.\n",
    "\n",
    "2.\n",
    "\n",
    "In the context of the \"Concrete\" dataset and considering the nature of concrete compressive strength prediction, I will consider using Random Forest. It offers a balance between interpretability and predictive accuracy, which is often desirable in practical applications. If the dataset is particularly complex and you need even higher accuracy, I would use Gradient Boosting.\n",
    "\n",
    "3.\n",
    "\n",
    "a. Hyperparameter Tuning: Optimize the hyperparameters of the tree-based models. For example, adjust the max_depth, n_estimators (in the case of Random Forest), and learning rate (in the case of Gradient Boosting). Grid search or random search can help identify the optimal hyperparameters.\n",
    "\n",
    "b.Interaction Features: Explore interactions between features. Create interaction terms that combine two or more features, which can help the model capture complex relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "1. \n",
    "The code was not generated by AI but from stratch.\n",
    "Here are the processes used to create the code:\n",
    "\n",
    "Data Source: The data is sourced from the Yellowbrick library's \"load_concrete\" function. This function loads the \"Concrete\" dataset.\n",
    "\n",
    "Import Libraries: The code imports the necessary Python libraries, including numpy, pandas, matplotlib, and seaborn, to handle data and create visualizations.\n",
    "\n",
    "Machine Learning Models: The code imports machine learning models (Decision Tree, Random Forest, and Gradient Boosting) from scikit-learn and instantiates these models with specified hyperparameters.\n",
    "\n",
    "Model Training and Validation: The code uses cross-validation to train and validate the models. It calculates the average training and validation R2 scores for each model. This step also involves using the \"r2_score\" metric for scoring the models.\n",
    "\n",
    "Results Visualization: The code creates a pandas DataFrame to organize and display the results, including training and validation R2 scores for each model.\n",
    "\n",
    "There were no significant challenges in creating this code since it's a standard workflow for training and evaluating machine learning models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 2: Classification (17.5 marks)\n",
    "\n",
    "You have been asked to develop code that can help the user classify different wine samples. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (2 marks)\n",
    "\n",
    "The data used for this task can be downloaded from UCI: https://archive.ics.uci.edu/dataset/109/wine\n",
    "\n",
    "Use the pandas library to load the dataset. You must define the column headers if they are not included in the dataset \n",
    "\n",
    "You will need to split the dataset into feature matrix `X` and target vector `y`. Which column represents the target vector?\n",
    "\n",
    "Print the size and type of `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size and type of X:\n",
      "(178, 13) <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Size and type of y:\n",
      "(178,) <class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import wine dataset\n",
    "# Define the column headers\n",
    "\n",
    "\n",
    "# Define the URL for the dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "\n",
    "# Define column headers for the dataset\n",
    "column_names = [\n",
    "    'Class',\n",
    "    'Alcohol',\n",
    "    'Malic_Acid',\n",
    "    'Ash',\n",
    "    'Alcalinity_of_Ash',\n",
    "    'Magnesium',\n",
    "    'Total_Phenols',\n",
    "    'Flavanoids',\n",
    "    'Nonflavanoid_Phenols',\n",
    "    'Proanthocyanins',\n",
    "    'Color_Intensity',\n",
    "    'Hue',\n",
    "    'OD280_OD315_of_Diluted_Wines',\n",
    "    'Proline'\n",
    "]\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "wine_data = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "# Split the dataset into feature matrix X and target vector y\n",
    "X = wine_data.drop('Class', axis=1)  # 'Class' column is the target, so we drop it\n",
    "y = wine_data['Class']\n",
    "\n",
    "# Print the size and type of X and y\n",
    "print(\"Size and type of X:\")\n",
    "print(X.shape, type(X))\n",
    "print(\"\\nSize and type of y:\")\n",
    "print(y.shape, type(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28af110",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataset to inspect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea266921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Class  Alcohol  Malic_Acid   Ash  Alcalinity_of_Ash  Magnesium  \\\n",
      "0      1    14.23        1.71  2.43               15.6        127   \n",
      "1      1    13.20        1.78  2.14               11.2        100   \n",
      "2      1    13.16        2.36  2.67               18.6        101   \n",
      "3      1    14.37        1.95  2.50               16.8        113   \n",
      "4      1    13.24        2.59  2.87               21.0        118   \n",
      "\n",
      "   Total_Phenols  Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  \\\n",
      "0           2.80        3.06                  0.28             2.29   \n",
      "1           2.65        2.76                  0.26             1.28   \n",
      "2           2.80        3.24                  0.30             2.81   \n",
      "3           3.85        3.49                  0.24             2.18   \n",
      "4           2.80        2.69                  0.39             1.82   \n",
      "\n",
      "   Color_Intensity   Hue  OD280_OD315_of_Diluted_Wines  Proline  \n",
      "0             5.64  1.04                          3.92     1065  \n",
      "1             4.38  1.05                          3.40     1050  \n",
      "2             5.68  1.03                          3.17     1185  \n",
      "3             7.80  0.86                          3.45     1480  \n",
      "4             4.32  1.04                          2.93      735  \n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "print(wine_data.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fc8fe",
   "metadata": {},
   "source": [
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97c6e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "missing_values = wine_data.isnull().sum()\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_values[missing_values > 0])\n",
    "wine_data = wine_data.fillna(wine_data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070956af",
   "metadata": {},
   "source": [
    "How many samples do we have of each type of wine?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b37a6fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples for each type of wine:\n",
      "Class\n",
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "wine_class_counts = wine_data['Class'].value_counts()\n",
    "\n",
    "# Print the counts for each type of wine\n",
    "print(\"Number of samples for each type of wine:\")\n",
    "print(wine_class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `SVC` and `DecisionTreeClassifier` from sklearn\n",
    "2. Instantiate models as `SVC()` and `DecisionTreeClassifier(max_depth = 3)`\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the average training and validation accuracy using `cross_validate` for the two different models listed in Step 3. For this case, use `scoring='accuracy'`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "#### Step 5.1: Compare Models\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Data Size          Model  Training Accuracy  Validation Accuracy\n",
      "0       142            SVC           0.698882             0.662808\n",
      "1       142  Decision Tree           0.994721             0.929310\n",
      "2       142            SVC           0.711225             0.711576\n",
      "3       142  Decision Tree           0.980562             0.929803\n",
      "4       142            SVC           0.674259             0.654926\n",
      "5       142  Decision Tree           0.994690             0.901478\n",
      "6       142            SVC           0.704176             0.718227\n",
      "7       142  Decision Tree           0.996476             0.929310\n",
      "8       142            SVC           0.690110             0.689655\n",
      "9       142  Decision Tree           0.985949             0.852463\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "# Initialize random state\n",
    "random_state = 0\n",
    "\n",
    "# Create a list of different random states for the loop\n",
    "random_states = [0, 1, 2, 3, 4]\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results = pd.DataFrame(columns=[\"Data Size\", \"Model\", \"Training Accuracy\", \"Validation Accuracy\"])\n",
    "\n",
    "# Loop through different random states and store results\n",
    "for state in random_states:\n",
    "    # Split the data into training and validation sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=state)\n",
    "\n",
    "    # Initialize the models\n",
    "    svc_model = SVC()\n",
    "    dt_model = DecisionTreeClassifier(max_depth=3, random_state=state)\n",
    "\n",
    "    # Cross-validate the SVC model\n",
    "    svc_scores = cross_validate(svc_model, X_train, y_train, scoring='accuracy', cv=5, return_train_score=True)\n",
    "\n",
    "    # Cross-validate the Decision Tree model\n",
    "    dt_scores = cross_validate(dt_model, X_train, y_train, scoring='accuracy', cv=5, return_train_score=True)\n",
    "\n",
    "    # Store the results in the DataFrame\n",
    "    results = pd.concat([results, pd.DataFrame({\n",
    "        \"Data Size\": [X_train.shape[0], X_train.shape[0]],\n",
    "        \"Model\": [\"SVC\", \"Decision Tree\"],\n",
    "        \"Training Accuracy\": [svc_scores['train_score'].mean(), dt_scores['train_score'].mean()],\n",
    "        \"Validation Accuracy\": [svc_scores['test_score'].mean(), dt_scores['test_score'].mean()]\n",
    "    })], ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e17878",
   "metadata": {},
   "source": [
    "#### Step 5.2: Visualize Classification Errors\n",
    "Which method gave the highest accuracy? Use this method to print the confusion matrix and classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "44b091a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[10  0  0]\n",
      " [ 1 12  0]\n",
      " [ 0  3 10]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      1.00      0.95        10\n",
      "           2       0.80      0.92      0.86        13\n",
      "           3       1.00      0.77      0.87        13\n",
      "\n",
      "    accuracy                           0.89        36\n",
      "   macro avg       0.90      0.90      0.89        36\n",
      "weighted avg       0.90      0.89      0.89        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Implement best model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Find the method with the highest validation accuracy\n",
    "best_model = results.loc[results['Validation Accuracy'].idxmax()]['Model']\n",
    "\n",
    "# Use the best model to make predictions on the validation set\n",
    "if best_model == 'SVC':\n",
    "    best_model = SVC()\n",
    "elif best_model == 'Decision Tree':\n",
    "    best_model = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "\n",
    "# Fit the best model on the entire training data\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "# Print the confusion matrix\n",
    "confusion = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "\n",
    "# Print the classification report\n",
    "report = classification_report(y_val, y_pred)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09d21b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Blues\", linewidths=.5, square=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5ef95947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.29      0.32        14\n",
      "           2       0.53      0.50      0.52        16\n",
      "           3       0.10      0.17      0.12         6\n",
      "\n",
      "    accuracy                           0.36        36\n",
      "   macro avg       0.33      0.32      0.32        36\n",
      "weighted avg       0.40      0.36      0.37        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Print the classification report\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. How do the training and validation accuracy change depending on the method used? Explain with values.\n",
    "1. What are two reasons why the support vector machines model did not work as well as the tree-based model?\n",
    "1. How many samples were incorrectly classified in step 5.2? \n",
    "1. In this case, is maximizing precision or recall more important? Why?\n",
    "\n",
    "*YOUR ANSWERS HERE*\n",
    "\n",
    "1.\n",
    "For SVC:\n",
    "\n",
    "Training Accuracy ranges from approximately 0.674 to 0.711, with an average of around 0.696.\n",
    "Validation Accuracy ranges from approximately 0.654 to 0.718, with an average of around 0.697.\n",
    "For Decision Trees:\n",
    "\n",
    "Training Accuracy ranges from approximately 0.980 to 0.996, with an average of around 0.989.\n",
    "Validation Accuracy ranges from approximately 0.852 to 0.929, with an average of around 0.905.\n",
    "\n",
    "The Decision Tree model consistently outperforms the SVC model in terms of both training and validation accuracy. The training accuracy is significantly higher for the Decision Tree, indicating that it can fit the training data better. However, it's important to note that the Decision Tree model may be overfitting to the training data, which is why the validation accuracy is still high but slightly lower than the training accuracy.\n",
    "\n",
    "2.\n",
    "Model Complexity: SVC might not be able to capture complex relationships in the data as effectively as Decision Trees, especially when the decision boundaries are non-linear. Decision Trees can create more complex decision boundaries.\n",
    "\n",
    "Hyperparameter Tuning: SVC requires careful tuning of hyperparameters such as the kernel type, regularization parameter (C), and gamma. If these hyperparameters are not tuned correctly for the specific dataset, the model's performance can suffer.\n",
    "\n",
    "3.\n",
    "In step 5.2, 36 samples were classified. The confusion matrix and classification report indicate that 4 samples were incorrectly classified.\n",
    "\n",
    "4.\n",
    "The importance of maximizing precision or recall depends on the specific goals and requirements of the classification task. Precision and recall are often in tension, meaning that improving one can lead to a decrease in the other.\n",
    "\n",
    "Precision measures the accuracy of positive predictions. In this context, it tells us how many of the samples predicted as positive are actually positive. Maximizing precision is important when false positives are costly or when you want to be very certain that the positive predictions are correct.\n",
    "\n",
    "Recall measures the ability of the model to capture all positive instances. In this context, it tells us how many of the actual positive samples were correctly predicted. Maximizing recall is important when missing positive cases (false negatives) is costly, and it's crucial to identify as many positive cases as possible.\n",
    "\n",
    "The choice between precision and recall depends on the specific use case. If, for example, you want to diagnose a life-threatening disease, you would prioritize maximizing recall to avoid missing any positive cases. However, if you're flagging potentially fraudulent transactions, you might prioritize precision to reduce false alarms. It's essential to consider the consequences of false positives and false negatives in your particular application.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "*DESCRIBE YOUR PROCESS HERE*\n",
    "\n",
    "I didnt use any AI tools for this part of the assignment.\n",
    "\n",
    "I followed the steps in the order you presented them:\n",
    "\n",
    "Step 1: Data Input\n",
    "\n",
    "Step 2: Data Preprocessing (completed in a previous conversation)\n",
    "\n",
    "Step 3: Implement Machine Learning Model\n",
    "\n",
    "Step 4: Validate Model\n",
    "\n",
    "Step 5: Visualize Results\n",
    "\n",
    "I did not meet with any significant challenges along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7358d",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "*ADD YOUR FINDINGS HERE*\n",
    "From this assignment, we can observe some patterns:\n",
    "\n",
    "Training Accuracy vs. Validation Accuracy: In most cases, the training accuracy is significantly higher than the validation accuracy for both the SVC and Decision Tree models. This is a common pattern and relates to the concept of overfitting. A high training accuracy indicates that the model is fitting the training data very well, but the drop in validation accuracy suggests that the model may not generalize as effectively to unseen data.\n",
    "\n",
    "Variability: There is some variability in both training and validation accuracy across different runs or datasets. This variability can be attributed to factors like random sampling and the size of the dataset. It's important to consider these variations when evaluating model performance.\n",
    "\n",
    "Decision Tree vs. SVC: The Decision Tree model consistently outperforms the SVC model in terms of accuracy, both in training and validation. This aligns with the concept that Decision Trees can fit the training data well and are prone to overfitting, but they can be effective in certain scenarios.\n",
    "\n",
    "The lectures on uncertainty estimates and decision functions are related to evaluating the models' confidence in their predictions. In this case, accuracy is used as a measure of predictive performance. However, accuracy may not always provide a complete picture, especially in imbalanced datasets. The lecture points out that for binary classification, we often want to examine false positives and false negatives, which can have different impacts depending on the specific problem.\n",
    "\n",
    "The decision tree-related content in the lectures is relevant to understanding the Decision Tree model's behavior. Decision Trees make predictions based on a series of if-else questions, and their depth can impact their ability to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "*ADD YOUR THOUGHTS HERE*\n",
    "While working on this assignment, I found it interesting to apply machine learning concepts to a real-world dataset and follow a structured machine learning workflow. It was motivating to see how different models performed and how accuracy can vary between training and validation data. However, one challenging aspect was handling the variations in accuracy across different runs, which emphasized the importance of robust model evaluation. Overall, I enjoyed the hands-on experience of working with machine learning models and real data but also recognized the need for a deeper dive into model evaluation techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21e53b",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (3 marks)\n",
    "\n",
    "Repeat Part 2 and compare the support vector machines model used to `LinearSVC(max_iter=5000)`. Does using `LinearSVC` improve the results? Why or why not?\n",
    "\n",
    "Is `LinearSVC` a good fit for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30fea72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC Training Accuracy: 0.971830985915493\n",
      "LinearSVC Validation Accuracy: 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giethang/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/Users/giethang/anaconda3/envs/ensf-ml/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Instantiate LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "linear_svc_model = LinearSVC(max_iter=5000, random_state=0)\n",
    "\n",
    "# Fit LinearSVC model to the data\n",
    "linear_svc_model.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the accuracy for LinearSVC\n",
    "linear_svc_train_accuracy = linear_svc_model.score(X_train, y_train)\n",
    "linear_svc_validation_accuracy = linear_svc_model.score(X_test, y_test)\n",
    "\n",
    "print(\"LinearSVC Training Accuracy:\", linear_svc_train_accuracy)\n",
    "print(\"LinearSVC Validation Accuracy:\", linear_svc_validation_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabc68a4",
   "metadata": {},
   "source": [
    "*ANSWER HERE*\n",
    "\n",
    "SVC:\n",
    "\n",
    "Training Accuracy: 0.711225\n",
    "Validation Accuracy: 0.711576\n",
    "LinearSVC:\n",
    "\n",
    "Training Accuracy: 0.971830985915493\n",
    "Validation Accuracy: 0.9444444444444444\n",
    "It is evident that the LinearSVC model outperforms the standard SVC in terms of both training and validation accuracy. LinearSVC achieved significantly higher accuracy on both the training and validation sets. This indicates that for this dataset, which seems to have a linearly separable or nearly linearly separable structure, a linear classifier like LinearSVC is more suitable and provides better results compared to the non-linear SVC.\n",
    "\n",
    "In summary, using LinearSVC improves the results in this case, and LinearSVC appears to be a good fit for this dataset given the high accuracy achieved in both training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c3b12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
